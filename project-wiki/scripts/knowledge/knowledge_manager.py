#!/usr/bin/env python3
"""
çŸ¥è¯†ç®¡ç†å™¨ - ç®¡ç†æ¸è¿›å¼çŸ¥è¯†æœç´¢å’Œç¼“å­˜
"""

import os
import sys
import json
from pathlib import Path
from typing import List, Dict, Optional, Set
from datetime import datetime
import re

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from search_knowledge import KnowledgeSearcher


class KnowledgeManager:
    """çŸ¥è¯†ç®¡ç†å™¨"""

    def __init__(self, wiki_dir: str = "./wiki", references_dir: str = "./wiki/references"):
        """
        åˆå§‹åŒ–çŸ¥è¯†ç®¡ç†å™¨

        Args:
            wiki_dir: Wiki ç›®å½•
            references_dir: çŸ¥è¯†åº“ç›®å½•
        """
        self.wiki_dir = Path(wiki_dir)
        self.references_dir = Path(references_dir)
        self.references_dir.mkdir(parents=True, exist_ok=True)

        self.searcher = KnowledgeSearcher(str(self.references_dir))

        # çŸ¥è¯†ç´¢å¼•
        self.knowledge_index_file = self.references_dir / ".knowledge-index.json"
        self.knowledge_index = self._load_knowledge_index()

        # ç¼“å­˜
        self.cache = {}

    def _load_knowledge_index(self) -> Dict:
        """åŠ è½½çŸ¥è¯†ç´¢å¼•"""
        if self.knowledge_index_file.exists():
            with open(self.knowledge_index_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}

    def _save_knowledge_index(self):
        """ä¿å­˜çŸ¥è¯†ç´¢å¼•"""
        with open(self.knowledge_index_file, 'w', encoding='utf-8') as f:
            json.dump(self.knowledge_index, f, indent=2, ensure_ascii=False)

    def register_knowledge(self, tech_stack: str, knowledge_type: str = "library", metadata: Dict = None):
        """
        æ³¨å†ŒçŸ¥è¯†

        Args:
            tech_stack: æŠ€æœ¯æ ˆåç§°
            knowledge_type: çŸ¥è¯†ç±»å‹
            metadata: å…ƒæ•°æ®
        """
        safe_name = re.sub(r'[^\w\-]', '_', tech_stack.lower())

        self.knowledge_index[safe_name] = {
            "tech_stack": tech_stack,
            "knowledge_type": knowledge_type,
            "metadata": metadata or {},
            "created_at": datetime.now().isoformat(),
            "updated_at": datetime.now().isoformat()
        }

        self._save_knowledge_index()

    def update_knowledge(self, tech_stack: str, metadata: Dict = None):
        """
        æ›´æ–°çŸ¥è¯†

        Args:
            tech_stack: æŠ€æœ¯æ ˆåç§°
            metadata: å…ƒæ•°æ®
        """
        safe_name = re.sub(r'[^\w\-]', '_', tech_stack.lower())

        if safe_name in self.knowledge_index:
            self.knowledge_index[safe_name]["metadata"].update(metadata or {})
            self.knowledge_index[safe_name]["updated_at"] = datetime.now().isoformat()
            self._save_knowledge_index()

    def get_knowledge_info(self, tech_stack: str) -> Optional[Dict]:
        """
        è·å–çŸ¥è¯†ä¿¡æ¯

        Args:
            tech_stack: æŠ€æœ¯æ ˆåç§°

        Returns:
            çŸ¥è¯†ä¿¡æ¯
        """
        safe_name = re.sub(r'[^\w\-]', '_', tech_stack.lower())
        return self.knowledge_index.get(safe_name)

    def list_knowledge(self, knowledge_type: str = None) -> List[Dict]:
        """
        åˆ—å‡ºæ‰€æœ‰çŸ¥è¯†

        Args:
            knowledge_type: çŸ¥è¯†ç±»å‹è¿‡æ»¤å™¨

        Returns:
            çŸ¥è¯†åˆ—è¡¨
        """
        knowledge_list = list(self.knowledge_index.values())

        if knowledge_type:
            knowledge_list = [k for k in knowledge_list if k["knowledge_type"] == knowledge_type]

        return knowledge_list

    def search_and_cache(self, tech_stack: str, knowledge_type: str = "library", force_refresh: bool = False) -> str:
        """
        æœç´¢å¹¶ç¼“å­˜çŸ¥è¯†

        Args:
            tech_stack: æŠ€æœ¯æ ˆåç§°
            knowledge_type: çŸ¥è¯†ç±»å‹
            force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°

        Returns:
            çŸ¥è¯†æ–‡ä»¶è·¯å¾„
        """
        # æ£€æŸ¥ç¼“å­˜
        if not force_refresh and tech_stack in self.cache:
            return self.cache[tech_stack]

        # æ£€æŸ¥çŸ¥è¯†æ˜¯å¦å­˜åœ¨
        if self.searcher.check_knowledge_exists(tech_stack) and not force_refresh:
            knowledge_file = self.searcher.get_knowledge_file(tech_stack)
            self.cache[tech_stack] = knowledge_file
            return knowledge_file

        # æœç´¢çŸ¥è¯†
        print(f"ğŸ” çŸ¥è¯†ä¸å­˜åœ¨ï¼Œæ­£åœ¨æœç´¢: {tech_stack}")
        search_data = self.searcher.search_knowledge(tech_stack, knowledge_type)
        knowledge_file = self.searcher.generate_knowledge_file(tech_stack, search_data)

        # æ³¨å†ŒçŸ¥è¯†
        self.register_knowledge(tech_stack, knowledge_type, {
            "search_keywords": search_data["search_keywords"],
            "search_results_count": len(search_data["search_results"])
        })

        # ç¼“å­˜
        self.cache[tech_stack] = knowledge_file

        return knowledge_file

    def get_knowledge(self, tech_stack: str, auto_search: bool = True) -> Optional[str]:
        """
        è·å–çŸ¥è¯†

        Args:
            tech_stack: æŠ€æœ¯æ ˆåç§°
            auto_search: æ˜¯å¦è‡ªåŠ¨æœç´¢

        Returns:
            çŸ¥è¯†æ–‡ä»¶è·¯å¾„
        """
        # æ£€æŸ¥ç¼“å­˜
        if tech_stack in self.cache:
            return self.cache[tech_stack]

        # æ£€æŸ¥çŸ¥è¯†æ˜¯å¦å­˜åœ¨
        knowledge_file = self.searcher.get_knowledge_file(tech_stack)

        if knowledge_file:
            self.cache[tech_stack] = knowledge_file
            return knowledge_file

        # è‡ªåŠ¨æœç´¢
        if auto_search:
            return self.search_and_cache(tech_stack)

        return None

    def extract_unknown_tech_stacks(self, text: str, known_stacks: Set[str] = None) -> List[str]:
        """
        ä»æ–‡æœ¬ä¸­æå–æœªçŸ¥çš„æŠ€æœ¯æ ˆ

        Args:
            text: æ–‡æœ¬å†…å®¹
            known_stacks: å·²çŸ¥æŠ€æœ¯æ ˆé›†åˆ

        Returns:
            æœªçŸ¥æŠ€æœ¯æ ˆåˆ—è¡¨
        """
        if known_stacks is None:
            known_stacks = set()

        # å¸¸è§æŠ€æœ¯æ ˆå…³é”®è¯æ¨¡å¼
        patterns = [
            r'\b[A-Z][a-zA-Z]+\.(js|py|java|go|rb|ts)\b',  # æ–‡ä»¶æ‰©å±•å
            r'\b[A-Z][a-zA-Z]+\b',  # å¤§å†™å¼€å¤´çš„è¯ï¼ˆå¯èƒ½æ˜¯åº“åï¼‰
            r'\b[a-z]+-[a-z]+\b',  # è¿å­—ç¬¦è¿æ¥çš„è¯ï¼ˆå¯èƒ½æ˜¯åº“åï¼‰
        ]

        tech_stacks = set()

        for pattern in patterns:
            matches = re.findall(pattern, text)
            tech_stacks.update(matches)

        # è¿‡æ»¤å·²çŸ¥æŠ€æœ¯æ ˆ
        unknown_stacks = [ts for ts in tech_stacks if ts not in known_stacks]

        return list(unknown_stacks)

    def batch_search(self, tech_stacks: List[str], knowledge_type: str = "library") -> Dict[str, str]:
        """
        æ‰¹é‡æœç´¢çŸ¥è¯†

        Args:
            tech_stacks: æŠ€æœ¯æ ˆåˆ—è¡¨
            knowledge_type: çŸ¥è¯†ç±»å‹

        Returns:
            æŠ€æœ¯æ ˆåˆ°çŸ¥è¯†æ–‡ä»¶çš„æ˜ å°„
        """
        results = {}

        for tech_stack in tech_stacks:
            try:
                knowledge_file = self.search_and_cache(tech_stack, knowledge_type)
                results[tech_stack] = knowledge_file
            except Exception as e:
                print(f"âŒ æœç´¢ {tech_stack} å¤±è´¥: {e}")
                results[tech_stack] = None

        return results

    def get_statistics(self) -> Dict:
        """
        è·å–ç»Ÿè®¡ä¿¡æ¯

        Returns:
            ç»Ÿè®¡ä¿¡æ¯
        """
        knowledge_list = self.list_knowledge()

        type_counts = {}
        for k in knowledge_list:
            t = k["knowledge_type"]
            type_counts[t] = type_counts.get(t, 0) + 1

        return {
            "total_knowledge": len(knowledge_list),
            "type_distribution": type_counts,
            "cache_size": len(self.cache),
            "oldest_knowledge": min(k["created_at"] for k in knowledge_list) if knowledge_list else None,
            "newest_knowledge": max(k["updated_at"] for k in knowledge_list) if knowledge_list else None
        }


def main():
    import argparse

    parser = argparse.ArgumentParser(description="çŸ¥è¯†ç®¡ç†å™¨")
    subparsers = parser.add_subparsers(dest="command", help="å­å‘½ä»¤")

    # æœç´¢å‘½ä»¤
    search_parser = subparsers.add_parser("search", help="æœç´¢çŸ¥è¯†")
    search_parser.add_argument("tech_stack", help="æŠ€æœ¯æ ˆåç§°")
    search_parser.add_argument("--type", choices=["library", "architecture", "pattern", "principle", "math"],
                              default="library", help="çŸ¥è¯†ç±»å‹")
    search_parser.add_argument("--force", action="store_true", help="å¼ºåˆ¶åˆ·æ–°")

    # åˆ—å‡ºå‘½ä»¤
    list_parser = subparsers.add_parser("list", help="åˆ—å‡ºçŸ¥è¯†")
    list_parser.add_argument("--type", help="çŸ¥è¯†ç±»å‹è¿‡æ»¤")

    # è·å–å‘½ä»¤
    get_parser = subparsers.add_parser("get", help="è·å–çŸ¥è¯†")
    get_parser.add_argument("tech_stack", help="æŠ€æœ¯æ ˆåç§°")
    get_parser.add_argument("--no-search", action="store_true", help="ä¸è‡ªåŠ¨æœç´¢")

    # ç»Ÿè®¡å‘½ä»¤
    subparsers.add_parser("stats", help="ç»Ÿè®¡ä¿¡æ¯")

    args = parser.parse_args()

    manager = KnowledgeManager()

    if args.command == "search":
        knowledge_file = manager.search_and_cache(args.tech_stack, args.type, args.force)
        print(f"âœ… çŸ¥è¯†æ–‡ä»¶: {knowledge_file}")

    elif args.command == "list":
        knowledge_list = manager.list_knowledge(args.type)
        print(f"\nğŸ“š çŸ¥è¯†åº“åˆ—è¡¨ ({len(knowledge_list)} é¡¹):\n")
        for k in knowledge_list:
            print(f"  â€¢ {k['tech_stack']} ({k['knowledge_type']})")
            print(f"    åˆ›å»ºæ—¶é—´: {k['created_at']}")
            if k.get('metadata'):
                print(f"    å…ƒæ•°æ®: {k['metadata']}")
            print()

    elif args.command == "get":
        knowledge_file = manager.get_knowledge(args.tech_stack, not args.no_search)
        if knowledge_file:
            print(f"âœ… çŸ¥è¯†æ–‡ä»¶: {knowledge_file}")
        else:
            print(f"âŒ çŸ¥è¯†ä¸å­˜åœ¨: {args.tech_stack}")

    elif args.command == "stats":
        stats = manager.get_statistics()
        print(f"\nğŸ“Š çŸ¥è¯†åº“ç»Ÿè®¡:\n")
        print(f"  æ€»çŸ¥è¯†æ•°: {stats['total_knowledge']}")
        print(f"  ç¼“å­˜å¤§å°: {stats['cache_size']}")
        print(f"  ç±»å‹åˆ†å¸ƒ:")
        for t, count in stats['type_distribution'].items():
            print(f"    {t}: {count}")
        if stats['oldest_knowledge']:
            print(f"  æœ€æ—©çŸ¥è¯†: {stats['oldest_knowledge']}")
        if stats['newest_knowledge']:
            print(f"  æœ€æ–°çŸ¥è¯†: {stats['newest_knowledge']}")
        print()

    else:
        parser.print_help()


if __name__ == "__main__":
    main()
